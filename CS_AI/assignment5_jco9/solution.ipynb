{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e655abb",
   "metadata": {
    "id": "ISfUJcAkHNbF"
   },
   "source": [
    "## Assignment 5 - Expectation Maximization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85aa270",
   "metadata": {
    "id": "oV2l22o5HNbH"
   },
   "source": [
    "## Overview\n",
    "\n",
    "Automatic image processing is a key component to many AI systems, including facial recognition and video compression, instance segmentation of images and point cloud data. One basic method for processing is segmentation, by which we divide an image into a fixed number of components in order to simplify its representation. For example, we can train a mixture of Gaussians to represent an image, and segment it according to the simplified representation as shown in the images below.\n",
    "\n",
    "![alt text](images/k6_Starry.png)\n",
    "\n",
    "Or we could perform a clustering of point cloud in order to separate different objects, backgrounds etc, as shown in the image below\n",
    "\n",
    "![alt text](images/pcd_clustered.gif)\n",
    "\n",
    "In this assignment, you will learn to perform image compression and point cloud segmentation. To this end, you will implement Gaussian mixture models and iteratively improve their performance. First you will perform segmentation on the \"Starry\" (`Starry.png`) and at the end run your algorithm on 3D point cloud data.\n",
    "\n",
    "To begin, you will implement several methods of image segmentation, with increasing complexity:\n",
    "\n",
    "1. Implement k-means clustering to segment a color image.\n",
    "\n",
    "2. Familiarize yourself with the algorithm by running it on simple dataset.\n",
    "\n",
    "3. Build a Gaussian mixture model to be trained with expectation-maximization.\n",
    "\n",
    "4. Experiment with varying the details of the Gaussian mixture model’s implementation.\n",
    "\n",
    "5. Implement and test a new metric called the Bayesian information criterion, which guarantees a more robust image segmentation.\n",
    "\n",
    "<br>\n",
    "\n",
    "- - -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1bd5c9e",
   "metadata": {
    "id": "Q3-iorXnHNbI"
   },
   "source": [
    "## Part 0: NumPy\n",
    "\n",
    "The concept of Vectorization was introduced in the last section of Assignment 4. For this assignment, please vectorize your code wherever possible using numpy arrays, instead of running for-loops over the images being processed.\n",
    "\n",
    "For example of how this might be useful, consider the following array:\n",
    "A = [12 34 1234 764 ...(has a million values)... 91, 78]\n",
    "\n",
    "Now you need to calculate another array B, which has the same dimensions as A above. Say each value in B is calculated as follows:\n",
    "(each value in B) = square_root_of(some constants pi log(k) * (each value in A))/7\n",
    "\n",
    "You might wish to use a for-loop to compute this. However, it will take really long to run on an array of this magnitude.\n",
    "Alternatively, you may choose to use numpy and perform this calculation in a single line. You can pass A as a numpy array and the entire calculation will be done in a line, resulting in B being populated with the corresponding values that come out of this formula.\n",
    "\n",
    "Check out **Basic Operation** section of the Numpy Tutorial if you are not familiar with numpy vector/matrix operations: https://docs.scipy.org/doc/numpy/user/quickstart.html#basic-operations. Please do check the resources linked in the assignment github readme.\n",
    "\n",
    "#### Please note that numpy.vectorize DOES NOT perform vectorization, it only does a loop. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27184e93",
   "metadata": {},
   "source": [
    "Let's look at a few examples below. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d742911",
   "metadata": {},
   "source": [
    "#### Element wise multiply\n",
    "Use np.multiply or operator * to perform element wise multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cae07bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using np.multiply()    \n",
      " [[ 1  4  9 16]\n",
      " [25 36 49 64]]\n",
      "using *  \n",
      " [[ 1  4  9 16]\n",
      " [25 36 49 64]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.array([[1,2,3,4], \n",
    "              [5,6,7,8]])\n",
    "y = np.array([[1,2,3,4], \n",
    "              [5,6,7,8]])\n",
    "output_multiply = np.multiply(x, y)\n",
    "output_op = x * y\n",
    "print(f'using np.multiply()    \\n {output_multiply}')\n",
    "print(f'using *  \\n {output_op}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b24d8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using np.power  \n",
      " [[ 1  4  9 16]\n",
      " [25 36 49 64]]\n"
     ]
    }
   ],
   "source": [
    "# in this case we can also do np.power, which is an element wise function that raise each entry of the array to the power of given number. Note a and b defined above are the same.͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "output_power = np.power(x, 2)\n",
    "print(f'using np.power  \\n {output_power}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da9a6ed",
   "metadata": {},
   "source": [
    "#### Inner product\n",
    "Use np.dot() or self.dot() to perform inner product between vectors. There are some nauance between 1d vector and higher dimension arrays.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efcf3892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using np.dot()    \n",
      " 70\n",
      "using self.dot()  \n",
      " 70\n"
     ]
    }
   ],
   "source": [
    "p = np.array([1,2,3,4])\n",
    "q = np.array([5,6,7,8])\n",
    "output_dot = np.dot(p, q)\n",
    "output_sdot = p.dot(q)\n",
    "print(f'using np.dot()    \\n {output_dot}')\n",
    "print(f'using self.dot()  \\n {output_sdot}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abf08937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using np.dot()    \n",
      " [[70]]\n",
      "using self.dot()  \n",
      " [[70]]\n"
     ]
    }
   ],
   "source": [
    "m = np.array([[1,2,3,4]])\n",
    "n = np.array([[5,6,7,8]])\n",
    "output_ndot = np.dot(m, n.T)\n",
    "output_nsdot = m.dot(n.T)\n",
    "print(f'using np.dot()    \\n {output_ndot}')\n",
    "print(f'using self.dot()  \\n {output_nsdot}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b3cffd",
   "metadata": {},
   "source": [
    "Technically, in the above example, a and b are 1 x 4 matrices. So we have to perform a transpose on b to align the dimension for matrix multiplication. More examples on Matrix multiplication are in the following."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba66327c",
   "metadata": {},
   "source": [
    "#### Matrix multiplication\n",
    "There are many ways to do matrix multiplication in Numpy. Notebly you can do np.dot(), self.dot(), operator '@', np.matmul, or einsum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca9525a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using np.dot()    \n",
      " [[ 30  70]\n",
      " [ 70 174]]\n",
      "using self.dot()  \n",
      " [[ 30  70]\n",
      " [ 70 174]]\n",
      "using operator @  \n",
      " [[ 30  70]\n",
      " [ 70 174]]\n",
      "using np.matmul  \n",
      " [[ 30  70]\n",
      " [ 70 174]]\n",
      "using np.einsum  \n",
      " [[ 30  70]\n",
      " [ 70 174]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[1,2,3,4], \n",
    "              [5,6,7,8]])\n",
    "y = np.array([[1,2,3,4], \n",
    "              [5,6,7,8]])\n",
    "output_ndot = np.dot(x, y.T)\n",
    "output_nsdot = x.dot(y.T)\n",
    "output_nop = x @ y.T\n",
    "output_matmul = np.matmul(x, y.T)\n",
    "output_esum = np.einsum('ij, jk-> ik', x, y.T)\n",
    "print(f'using np.dot()    \\n {output_ndot}')\n",
    "print(f'using self.dot()  \\n {output_nsdot}')\n",
    "print(f'using operator @  \\n {output_nop}')\n",
    "print(f'using np.matmul  \\n {output_matmul}')\n",
    "print(f'using np.einsum  \\n {output_esum}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a1e47b",
   "metadata": {},
   "source": [
    "#### Einsum\n",
    "Note einsum can do a lot more. For full documentation, see https://numpy.org/doc/stable/reference/generated/numpy.einsum.html. Some good examples are listed in https://stackoverflow.com/questions/26089893/understanding-numpys-einsum, https://rockt.github.io/2018/04/30/einsum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1890864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trace of the product of x and y: 125120.74136559803\n",
      "9.27 ms ± 1.04 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "318 µs ± 29.9 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# a and b are defined same as before͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "m, n = 1000, 500\n",
    "\n",
    "x = np.random.rand(m, n)\n",
    "y = np.random.rand(m, n)\n",
    "# trace of the matrix multiplication͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "output_trace_fast = np.einsum('ij, ji->', x, y.T)\n",
    "print(f'Trace of the product of x and y: {output_trace_fast}')\n",
    "# compare time spent on computing͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉 \n",
    "# trace of the matrix multiplication͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "# vanilla͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "%timeit np.trace(x.dot(y.T))\n",
    "# einsum͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "%timeit output_trace_fast = np.einsum('ij, ji->', x, y.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa586f8",
   "metadata": {},
   "source": [
    "### Additional useful NumPy tricks and functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b861a9a",
   "metadata": {},
   "source": [
    "#### Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec519391",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "[9 8 7 6 5 4 3 2 1 0]\n",
      "[False  True False False False False False False False False]\n",
      "(array([1]),)\n",
      "[ 0 11  2  3  4  5  6  7  8  9]\n"
     ]
    }
   ],
   "source": [
    "# axis wise͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "x = np.random.rand(50, 50, 50)\n",
    "y = x[0, :, :]\n",
    "\n",
    "# reverse order͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "x = np.arange(10)\n",
    "print(x)\n",
    "# general rule: start:end:step, a negative step means reverse͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "print(x[::-1])\n",
    "\n",
    "# conditional indexing and np.where͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "x = np.arange(10)\n",
    "print(x==1)\n",
    "print(np.where(x==1))\n",
    "# replace the entry where x has value 1, with a new value of 11͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "# note the second and third arguments are for values where the condition fails !(x!=1) = x==1͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "print(np.where(x!=1, x, 11))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d73357",
   "metadata": {},
   "source": [
    "#### A list of useful functions and operators\n",
    "1. `np.concatenate()` - let you put together two arrays along certain axis\n",
    "2. `np.zeros(), np.ones()` - create array of zeros and ones with specified dimension\n",
    "3. `x[start:end]` - slicing an array from 'start' position to 'end' position, can be used for different axises\n",
    "4. `np.diagonal()` - create a matrix with diagonal element specified (a 1-D array). Will return diagonal elements when passing high dimensional arraies.\n",
    "5. `np.reshape()` - reshape the dimension of your array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55f7e6a",
   "metadata": {
    "id": "dUhnhEdvHNbJ"
   },
   "source": [
    "## Part 1: K-means Clustering (39 pts)\n",
    "\n",
    "One easy method for image segmentation is to simply cluster all similar data points together and then replace their values with the mean value. Thus, we'll warm up using k-means clustering. This will also provide a baseline to compare with your segmentation. Please note that clustering will come in handy later.\n",
    "\n",
    "Fill out `get_initial_means()`, `k_means_step()` functions below.\n",
    "\n",
    "In `get_initial_means()`, you should choose  k random points from the data (without replacement) to use as initial cluster means.\n",
    "\n",
    "Your code will be unit tested automatically when you run the cell (`Cell > Run Cells OR Shift + Enter`).\n",
    "\n",
    "#### Try to vectorize the code for it to run faster. Without vectorization it takes 25-30 minutes for the code to run.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e6e11f6",
   "metadata": {
    "id": "lHRbOkJnHNbJ",
    "outputId": "3405377b-cd38-4bba-d253-75d7a7163353"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# Run this cell and check if you have all necessary modules͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "from ipywidgets import *\n",
    "import mixture_tests as tests\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as pat\n",
    "from scipy.stats import norm\n",
    "import os\n",
    "import numpy as np\n",
    "from helper_functions import *\n",
    "# Please don't modify this cell͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20f0060f",
   "metadata": {
    "id": "vjJX8ByfHNbN"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "import numpy as np\n",
    "from helper_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be95c40d",
   "metadata": {
    "id": "psHj3p1wHNbQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UnitTest passed successfully!\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "def get_initial_means(array, k):\n",
    "    \"\"\"\n",
    "    Picks k random points from the 2D array \n",
    "    (without replacement) to use as initial \n",
    "    cluster means\n",
    "    \n",
    "    \n",
    "    params:\n",
    "    array = numpy.ndarray[numpy.ndarray[float]] - m x n | datapoints x features\n",
    "\n",
    "    k = int\n",
    "\n",
    "    returns:\n",
    "    initial_means = numpy.ndarray[numpy.ndarray[float]]\n",
    "    \"\"\"\n",
    "    # TODO: finish this function͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "    return array[np.random.choice(array.shape[0], k, False), :]\n",
    "    \n",
    "########## DON'T WRITE ANY CODE OUTSIDE THE FUNCTION! ################͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "##### CODE BELOW IS USED FOR RUNNING LOCAL TEST DON'T MODIFY IT ######͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "tests.K_means_test().test_initial_means(get_initial_means)\n",
    "################ END OF LOCAL TEST CODE SECTION ######################͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0444de2",
   "metadata": {
    "id": "_txM46_YHNbT",
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UnitTest passed successfully!\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "def k_means_step(X, k, means):\n",
    "    \"\"\"\n",
    "    A single update/step of the K-means algorithm\n",
    "    Based on a input X and current mean estimate,\n",
    "    predict clusters for each of the pixels and \n",
    "    calculate new means. \n",
    "    params:\n",
    "    X = numpy.ndarray[numpy.ndarray[float]] - m x n | pixels x features (already flattened)\n",
    "    k = int\n",
    "    means = numpy.ndarray[numpy.ndarray[float]] - k x n\n",
    "\n",
    "    returns:\n",
    "    (new_means, clusters)\n",
    "    new_means = numpy.ndarray[numpy.ndarray[float]] - k x n\n",
    "    clusters = numpy.ndarray[int] - m sized vector\n",
    "    \"\"\"\n",
    "    # TODO: finish this function͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "    clusters = np.zeros(len(X))\n",
    "    s = (k,X.shape[1])\n",
    "    new_means = np.zeros(s)\n",
    "    \n",
    "    \n",
    "    for a in range(len(X)):\n",
    "        temp = X[a]\n",
    "        last = 10000000\n",
    "        index = 0\n",
    "        for i in range(np.size(means,0)):\n",
    "            total = np.sqrt(np.sum(np.power((np.subtract(temp, means[i])), 2)))\n",
    "            if total < last:\n",
    "                last = total\n",
    "                index = i\n",
    "        clusters[a] = index\n",
    "        \n",
    "    for d in range(k):   \n",
    "        total = np.zeros(np.size(X,1))\n",
    "        total_size = 0\n",
    "        for i in range(len(clusters)):\n",
    "            if clusters[i] == d:\n",
    "                total = np.add((X[i]), total)\n",
    "                total_size+=1\n",
    "        if total_size != 0:\n",
    "            average = np.multiply(total,(1/total_size))\n",
    "        else:\n",
    "            average = np.zeros(np.size(X,1))\n",
    "        new_means[d] = average\n",
    "        \n",
    "    return (new_means, clusters)\n",
    "########## DON'T WRITE ANY CODE OUTSIDE THE FUNCTION! ################͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "##### CODE BELOW IS USED FOR RUNNING LOCAL TEST DON'T MODIFY IT ######͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "tests.K_means_test().test_k_means_step(k_means_step)\n",
    "################ END OF LOCAL TEST CODE SECTION ######################͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84ae4bb",
   "metadata": {
    "id": "RkmRHcLeHNbW"
   },
   "source": [
    "#### K-means - Visualizing the results\n",
    "\n",
    "Now that you are done with the K-means step implementation lets try to visualize what's happening if you repeat these steps multiple times.\n",
    "\n",
    "**You don't need to be implementing anything in the next cells until Image Segmentation Section**, but you are highly encouraged to play with parameters and datasets, to get a sense of what is happening at every algorithm iteration step.\n",
    "\n",
    "Feel free to explore and improve the function below, it will be used for visualizing K-means progress\n",
    "but it's not required and WON'T effect your grade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ba5c4c5",
   "metadata": {
    "id": "P-r7LryvHNbW"
   },
   "outputs": [],
   "source": [
    "# This cell contains a code for loading a dataset from the `data` folder͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "# Each of these datasets contains synthtic (generated) data͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "# You can simply run this cell for now and come back to it later if you want to make changes͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "# Make sure you implemented everything in cells above and passed the unittests͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "def K_means_2D_dataset(dataset_index, K):\n",
    "    # Load the dataset from data folder͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "    X = np.loadtxt(\"data/%d_dataset_X.csv\" % dataset_index, delimiter=\",\")\n",
    "    print(\"The dataset is of a size:\", X.shape)\n",
    "\n",
    "    # Load the labels͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "    # Clustering is unsupervised method, where no labels are provided͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "    # However, since we generated the data outselves we know the clusters,͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "    # and load them for illustration purposes.͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "    y = np.int16(np.loadtxt(\"data/%d_dataset_y.csv\" % dataset_index, delimiter=\",\"))\n",
    "\n",
    "    # Feel free to edit the termination condition for the K-means algorithm͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "    # Currently is just runs for n_iterations, before terminating͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "    n_iterations = 10\n",
    "    m,n = X.shape\n",
    "    means = get_initial_means(X,K)\n",
    "    clusters = np.zeros([n])\n",
    "    # keeping track of how clusters and means changed, for visualization purposes͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "    means_history = [means]\n",
    "    clusters_history = [clusters] \n",
    "    for iteration_i in range(n_iterations):\n",
    "        means, clusters = k_means_step(X, K, means)\n",
    "        clusters_history.append(clusters)\n",
    "\n",
    "    return X, y, means_history, clusters_history\n",
    "\n",
    "# Things to try:͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "# - Try different initialization to see check initialization robustness͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "# - Improve the termination condition (you will be able to reuse later as well!)͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "# - Try creating you own dataset in the `data/` folder͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dee92758",
   "metadata": {
    "id": "weDmGThLHNbY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset is of a size: (1000, 2)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61d6931731fc4b768f7cebaf8e436750",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=5, description='i', max=10, min=1), Output()), _dom_classes=('widget-int…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# RUN - TRY DIFFERENT PARAMETERS - REPEAT͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "dataset_index = 2 # for different dataset change it to number from [0,4]\n",
    "K = 5 # Number of clusters - play with this number\n",
    "\n",
    "X, y, means_history, clusters_history = K_means_2D_dataset(dataset_index, K)\n",
    "\n",
    "# This is an interactive cell to see the progress of training your K-means algorithm.͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "# Feel free to improve the visualization code and share it with your classmates on Piazza͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "def get_cluster(i):\n",
    "    clusters = clusters_history[i] # Get the clusters from K-means' i-th iteration\n",
    "    plt.figure(None, figsize=(15,6)) # Set the plot size\n",
    "    plt.suptitle('Drag the slider to see the algorthm training progress')\n",
    "    ax1=plt.subplot(1, 2, 1)\n",
    "    ax1.set_title('K-means clusters - step %d' % i)\n",
    "    for k in range(K):\n",
    "        plt.plot(X[clusters==k,0], X[clusters==k,1], '.') # \n",
    "        # Try to plot the centers of the clusters͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉 \n",
    "        # You can access them by calling means_history[i]͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "        # How could you plot the area that belong to that cluster?͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "\n",
    "    # Just to get a flavour of how the data looks like͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "    ax2=plt.subplot(1, 2, 2)\n",
    "    ax2.set_title('Ground truth clusters')\n",
    "    for i in np.unique(y):\n",
    "        ax2.plot(X[y==i,0],X[y==i,1],'.')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "interactive(get_cluster, i=(1,len(clusters_history)-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a174ba3",
   "metadata": {
    "id": "K-iiPyzuHNbd"
   },
   "source": [
    "### Image segmentation\n",
    "2D data clustering is all cool and all but now it's time to use K-means for the image compression! \n",
    "\n",
    "Fill in the `k_means_segment()` function below, you will find your `k_means_step()` and `get_initial_means()` very handy here. \n",
    "\n",
    "You will separate the provided RGB values into k clusters using the k-means algorithm, then return an updated version of the image with the original values replaced with the corresponding cluster center values.\n",
    "\n",
    "Your convergence test should be whether the assigned clusters stop changing. Note that this convergence test is rather slow. When no initial cluster means (`initial_means`) are provided, you need to initialize them yourself, based on the given k.\n",
    "\n",
    "For this part of the assignment, since clustering is best used on multidimensional data, we will be using the color image `Starry.png`.\n",
    "\n",
    "Please pay close attention to the dimensions of the data. In the `k_means_step()` you were working with m x n data, here the input is an image (`image_values`) which has a shape of **rows x columns x color_channels**.\n",
    "\n",
    "The function should return an updated version of the image with the original values replaced with the corresponding cluster values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db838d55",
   "metadata": {
    "id": "J9XUDTQHHNbd",
    "scrolled": true,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def k_means_segment(image_values, k=3, initial_means=None):\n",
    "    \"\"\"\n",
    "    Separate the provided RGB values into\n",
    "    k separate clusters using the k-means algorithm,\n",
    "    then return an updated version of the image\n",
    "    with the original values replaced with\n",
    "    the corresponding cluster values.\n",
    "\n",
    "    params:\n",
    "    image_values = numpy.ndarray[numpy.ndarray[numpy.ndarray[float]]] - r x c x ch\n",
    "    k = int\n",
    "    initial_means = numpy.ndarray[numpy.ndarray[float]] or None\n",
    "\n",
    "    returns:\n",
    "    updated_image_values = numpy.ndarray[numpy.ndarray[numpy.ndarray[float]]] - r x c x ch\n",
    "    \"\"\"\n",
    "    # TODO: finish this function͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "\n",
    "    row = np.shape(image_values)[0]\n",
    "    col = np.shape(image_values)[1]\n",
    "    values = np.shape(image_values)[2]\n",
    "    \n",
    "    if np.size(initial_means) == 0:\n",
    "        initial_means = get_initial_means(updated_image_values, 3)\n",
    "        \n",
    "    \n",
    "    updated_image_values = np.reshape(image_values, ((np.multiply(row,col)), values))\n",
    "\n",
    "    \n",
    "    means, label = k_means_step(updated_image_values, k, initial_means)\n",
    "\n",
    "    last = initial_means\n",
    "    \n",
    "    while (np.array_equal(last,means) == False):\n",
    "        last = means \n",
    "        means, label = k_means_step(updated_image_values, k, means)\n",
    "    \n",
    "    for i in range(k):\n",
    "        updated_image_values[label == i] = means[i]\n",
    "    \n",
    "    updated_image_values = np.reshape(updated_image_values, (row, col, values))\n",
    "    \n",
    "    return updated_image_values\n",
    "        \n",
    "########## DON'T WRITE ANY CODE OUTSIDE THE FUNCTION! ################͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "##### CODE BELOW IS USED FOR RUNNING LOCAL TEST DON'T MODIFY IT ######͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "tests.K_means_test().test_k_means(k_means_segment)\n",
    "################ END OF LOCAL TEST CODE SECTION ######################͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08335d33",
   "metadata": {
    "id": "jKU3OdmwHNbf"
   },
   "source": [
    "### Visulizing K-means segmentation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d123991a",
   "metadata": {
    "id": "vbj3ETyrHNbi"
   },
   "outputs": [],
   "source": [
    "k=5 # number of clusters - feel free to play with it\n",
    "\n",
    "image_values = image_to_matrix('images/Starry.png')\n",
    "# Play with the K value below to see the effect number of clusters have͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "new_image = k_means_segment(image_values, k=k)\n",
    "\n",
    "plt.figure(None,figsize=(9,12))\n",
    "plt.imshow(new_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47f15aa",
   "metadata": {
    "id": "Ty-hePOgHNb1"
   },
   "source": [
    "# You can reuse the K-means visualization code from previous section to show the training progress on the image for different iterations and even numbers of clusters.\n",
    "\n",
    "- - -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece600af",
   "metadata": {
    "id": "n-EVOn9nHNb2"
   },
   "source": [
    "## Part 2: Implementing a Multivariate Gaussian Mixture Model (60 pts)\n",
    "\n",
    "Next, we will step beyond clustering and implement a complete Gaussian mixture model.\n",
    "\n",
    "But, before you dive into the code, you are highly encouraged to go over `read/gaussians.pdf` file before you start, to familiarize yourself with multivariate case of the Gaussian distribution.\n",
    "\n",
    "In addition to that, there is a great ~17 minute video where Alexander Ihler goes over nuts and bolds of the multivariate EM algorithm details on Youtube:\n",
    "https://www.youtube.com/watch?v=qMTuMa86NzU\n",
    "\n",
    "Another resource you can refer to is the `read/em.pdf` document attached, which is a chapter from Pattern Recognition and Machine Learning book by Christopher M. Bishop.\n",
    "\n",
    "- - - \n",
    "\n",
    "Now, it's time to complete the implementation of the functions below what will later assemble into a Multivariate Gaussian Expectation Maximization algorithm:\n",
    "\n",
    "1. Calculate the probability of a given data point (e.g. rgb value of a pixel) of belonging to a specific Gaussian component. (7 points)\n",
    "\n",
    "2. Use expectation-maximization (EM) to train the model to represent the image as a mixture of Gaussians. (20 points)\n",
    "\n",
    "To initialize EM, set each component's mean to the means value of randomly chosen pixels (same as for K-means) and calculate covariances based on the selected means, and set the mixing coefficients to a uniform distribution. \n",
    "\n",
    "We've set the convergence condition for you in `default_convergence()` (see `helper_functions.py` file): if the new likelihood is within 10% of the previous likelihood for 10 consecutive iterations, the model has converged.\n",
    "\n",
    "**Note:** there are packages that can run EM automagically, but you have to implement your own version of EM without using these extra packages. **It also means that you are not allowed to look into any implementations of the algorithms, e.g scikit-learn and many others. NumPy is your only tool here.** \n",
    "\n",
    "3. Calculate the log likelihood of the trained model. (7 points)\n",
    "4. Segment the image according to the trained model. (7 points)\n",
    "5. Determine the best segmentation by iterating over model training and scoring, since EM isn't guaranteed to converge to the global maximum. (7 points)\n",
    "\n",
    "It'd be helpful to implement the above functions in the following order - \n",
    "1. initialize_parameters\n",
    "2. prob\n",
    "3. E_step\n",
    "4. M_step\n",
    "5. likelihood \n",
    "6. train_model\n",
    "7. cluster\n",
    "8. segment\n",
    "9. best_segment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa373bd6",
   "metadata": {
    "id": "bdcZyf4tHNb7"
   },
   "source": [
    "### Warning: You may lose all marks for this part if your code runs for too long.\n",
    "\n",
    "**You will need to vectorize your code in this part. Specifically, the method E_step() and M_step() which make up the train_model(), perform operations using numpy arrays. These are time-sensitive functions and will be called over and over as you proceed with this assignment.**\n",
    "\n",
    "For the synthetic data test which we provide to check if your training is working, the set is too small and it won't make a difference. But with the actual image that we use ahead, for-loops won't do good. Vectorized code would take under 30 seconds to converge which would typically involve about 15-20 iterations with the convergence function we have here. Inefficient code that uses loops or iterates over each pixel value sequentially, will take hours to run. You don't want to do that.\n",
    "\n",
    "---\n",
    "\n",
    "The following cell (compute_sigma) will not be graded, but we highly recommend using this function and paired test to make sure your covariance matrix implementation is correct. Computing the covariance matrix incorrectly can result in problems that become extremely hard to debug later in the assignment so please take advantage of this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "ceb9bd63",
   "metadata": {
    "id": "ZtWDrD6wHNb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UnitTest passed successfully!\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "def compute_sigma(X, MU):\n",
    "    \"\"\"\n",
    "    Calculate covariance matrix, based in given X and MU values\n",
    "    \n",
    "    params:\n",
    "    X = numpy.ndarray[numpy.ndarray[float]] - m x n\n",
    "    MU = numpy.ndarray[numpy.ndarray[float]] - k x n\n",
    "    \n",
    "    returns:\n",
    "    SIGMA = numpy.ndarray[numpy.ndarray[numpy.ndarray[float]]] - k x n x n\n",
    "    \"\"\"\n",
    "    # TODO: finish this function͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "    \n",
    "    answer = np.zeros(((np.shape(MU)[0]), (np.shape(MU)[1]), (np.shape(MU)[1])))\n",
    "    for i in range((np.shape(MU)[0])):\n",
    "        m = np.shape(X)[0]\n",
    "        sub = np.subtract(X,MU[i])\n",
    "        trans = np.transpose(sub)\n",
    "        mult = np.matmul(trans, sub)\n",
    "        answer[i] = np.divide(mult, m)\n",
    "    return answer\n",
    "\n",
    "########## DON'T WRITE ANY CODE OUTSIDE THE FUNCTION! ################͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "##### CODE BELOW IS USED FOR RUNNING LOCAL TEST DON'T MODIFY IT ######͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "tests.GMMTests().test_gmm_covariance(compute_sigma)\n",
    "################ END OF LOCAL TEST CODE SECTION ######################͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86f3a20",
   "metadata": {},
   "source": [
    "Same as in K-means you will be working with the data of size (m x n). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "b09241d1",
   "metadata": {
    "id": "fzlJezxTHNb3",
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UnitTest passed successfully!\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "def initialize_parameters(X, k):\n",
    "    \"\"\"\n",
    "    Return initial values for training of the GMM\n",
    "    Set component mean to a random\n",
    "    pixel's value (without replacement),\n",
    "    based on the mean calculate covariance matrices,\n",
    "    and set each component mixing coefficient (PIs)\n",
    "    to a uniform values\n",
    "    (e.g. 4 components -> [0.25,0.25,0.25,0.25]).\n",
    "    \n",
    "    params:\n",
    "    X = numpy.ndarray[numpy.ndarray[float]] - m x n\n",
    "    k = int\n",
    "    \n",
    "    returns:\n",
    "    (MU, SIGMA, PI)\n",
    "    MU = numpy.ndarray[numpy.ndarray[float]] - k x n\n",
    "    SIGMA = numpy.ndarray[numpy.ndarray[numpy.ndarray[float]]] - k x n x n\n",
    "    PI = numpy.ndarray[float] - k \n",
    "    \"\"\"\n",
    "    # TODO: finish this function͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "    # Hint: for initializing SIGMA you could choose to use compute_sigma͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "\n",
    "    MU = get_initial_means(X, k)\n",
    "    SIGMA = compute_sigma(X, MU)\n",
    "    PI = (np.ones(k))\n",
    "    PI.fill(1/k)\n",
    "    return (MU, SIGMA, PI)\n",
    "########## DON'T WRITE ANY CODE OUTSIDE THE FUNCTION! ################͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "##### CODE BELOW IS USED FOR RUNNING LOCAL TEST DON'T MODIFY IT ######͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "tests.GMMTests().test_gmm_initialization(initialize_parameters)\n",
    "################ END OF LOCAL TEST CODE SECTION ######################͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e552bc9",
   "metadata": {
    "id": "1II4ri1THNcD"
   },
   "source": [
    "# NOTE:\n",
    "\n",
    "### Be careful when coding up prob() below. It is fine for prob() to take the vectorized approach, but you may have to adjust your implementation to handle both cases. Specifically the case where x is a single datapoint and where x is an entire array of datapoints.\n",
    "\n",
    "Note: prob function below gives a probability density estimate which we loosely (and definitely not accurately) call probability. As you can imagine the density function can take any value and can certainly be greater than 1. The prob function isn't really calculating probability but probability density."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "45a3b64e",
   "metadata": {
    "id": "AKudaHqgHNcE",
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UnitTest passed successfully!\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "def prob(x, mu, sigma):\n",
    "    \"\"\"Calculate the probability of x (a single\n",
    "    data point or an array of data points) under the\n",
    "    component with the given mean and covariance.\n",
    "    The function is intended to compute multivariate\n",
    "    normal distribution, which is given by N(x;MU,SIGMA).\n",
    "\n",
    "    params:\n",
    "    x = numpy.ndarray[float] (for single datapoint) \n",
    "        or numpy.ndarray[numpy.ndarray[float]] (for array of datapoints)\n",
    "    mu = numpy.ndarray[float]\n",
    "    sigma = numpy.ndarray[numpy.ndarray[float]]\n",
    "\n",
    "    returns:\n",
    "    probability = float (for single datapoint) \n",
    "                or numpy.ndarray[float] (for array of datapoints)\n",
    "    \"\"\"\n",
    "    # TODO: finish this function͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "    \n",
    "    \n",
    "    if x.size <= 3:\n",
    "        co = np.divide(1,(((np.sqrt((np.power((2*(np.pi)),len(x))) * (np.linalg.det(sigma)))))))\n",
    "        sub = np.subtract(x,mu)\n",
    "        trans = np.transpose(np.subtract(x,mu))\n",
    "        mult = (np.matmul(sub,np.linalg.pinv(sigma)))\n",
    "        multtwo = (np.matmul(mult,trans))\n",
    "        val = (-0.5)*multtwo\n",
    "        answer = co * np.exp(val)\n",
    "    else:\n",
    "        co = np.divide(1,(np.sqrt((np.power(((np.multiply(2,np.pi))),np.shape(x)[1])) * (np.linalg.det(sigma)))))\n",
    "\n",
    "        sub = (np.subtract(x,mu))\n",
    "\n",
    "        trans = (np.transpose(np.subtract(x,mu)))\n",
    "\n",
    "        mult = np.matmul(sub,(np.linalg.pinv(sigma)))\n",
    "        \n",
    "        multtwo = (np.einsum('ij,ji->i', mult,trans))\n",
    "        \n",
    "        val = np.multiply(0.5,multtwo)\n",
    "        fin = np.multiply(-1,val)\n",
    "        answer = np.multiply(co,(np.exp(fin)))\n",
    "    return answer\n",
    "\n",
    "########## DON'T WRITE ANY CODE OUTSIDE THE FUNCTION! ################͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "##### CODE BELOW IS USED FOR RUNNING LOCAL TEST DON'T MODIFY IT ######͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "tests.GMMTests().test_gmm_prob(prob)\n",
    "################ END OF LOCAL TEST CODE SECTION ######################͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "8975b9ae",
   "metadata": {
    "id": "Q4Zd5XXgHNcJ",
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UnitTest passed successfully!\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "def E_step(X,MU,SIGMA,PI,k):\n",
    "    \"\"\"\n",
    "    E-step - Expectation \n",
    "    Calculate responsibility for each\n",
    "    of the data points, for the given \n",
    "    MU, SIGMA and PI.\n",
    "    \n",
    "    params:\n",
    "    X = numpy.ndarray[numpy.ndarray[float]] - m x n\n",
    "    MU = numpy.ndarray[numpy.ndarray[float]] - k x n\n",
    "    SIGMA = numpy.ndarray[numpy.ndarray[numpy.ndarray[float]]] - k x n x n\n",
    "    PI = numpy.ndarray[float] - k\n",
    "    k = int\n",
    "    \n",
    "    returns:\n",
    "    responsibility = numpy.ndarray[numpy.ndarray[float]] - k x m\n",
    "    \"\"\"\n",
    "    # TODO: finish this function͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "    ric = np.zeros((k, (np.shape(X)[0])))\n",
    "    \n",
    "    for i in range(k):\n",
    "        temp = np.multiply(PI[i],(prob(X,MU[i],SIGMA[i])))\n",
    "        ric[i] = temp\n",
    "        \n",
    "    total = np.sum(ric, axis=0)\n",
    "    answer = np.divide(ric,total)\n",
    "    \n",
    "    return answer\n",
    "    \n",
    "########## DON'T WRITE ANY CODE OUTSIDE THE FUNCTION! ################͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "##### CODE BELOW IS USED FOR RUNNING LOCAL TEST DON'T MODIFY IT ######͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "tests.GMMTests().test_gmm_e_step(E_step)\n",
    "################ END OF LOCAL TEST CODE SECTION ######################͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "74778f64",
   "metadata": {
    "id": "IU6IEwZHHNcM",
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UnitTest passed successfully!\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "def M_step(X, r, k):\n",
    "    \"\"\"\n",
    "    M-step - Maximization\n",
    "    Calculate new MU, SIGMA and PI matrices\n",
    "    based on the given responsibilities.\n",
    "    \n",
    "    params:\n",
    "    X = numpy.ndarray[numpy.ndarray[float]] - m x n\n",
    "    r = numpy.ndarray[numpy.ndarray[float]] - k x m\n",
    "    k = int\n",
    "    \n",
    "    returns:\n",
    "    (new_MU, new_SIGMA, new_PI)\n",
    "    new_MU = numpy.ndarray[numpy.ndarray[float]] - k x n\n",
    "    new_SIGMA = numpy.ndarray[numpy.ndarray[numpy.ndarray[float]]] - k x n x n\n",
    "    new_PI = numpy.ndarray[float] - k\n",
    "    \"\"\"\n",
    "    # TODO: finish this function͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏\n",
    "    R = np.sum(r,axis=1)\n",
    "    new_PI = np.divide(R, np.shape(X)[0])\n",
    "    \n",
    "    new_MU = np.divide((np.dot(r,X)),R.reshape(-1, 1))\n",
    "    \n",
    "    new_SIGMA = []\n",
    "    for i in range(k):\n",
    "        center = X - new_MU[i]\n",
    "        mult = np.multiply(r[i],(np.transpose(center)))\n",
    "        dot = np.dot(mult, center)\n",
    "        temp = np.divide(dot, R[i])\n",
    "        new_SIGMA.append(temp)\n",
    "        \n",
    "    new_SIGMA = np.array(new_SIGMA)\n",
    "    \n",
    "    return (new_MU, new_SIGMA, new_PI)\n",
    "\n",
    "########## DON'T WRITE ANY CODE OUTSIDE THE FUNCTION! ################͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "##### CODE BELOW IS USED FOR RUNNING LOCAL TEST DON'T MODIFY IT ######͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "tests.GMMTests().test_gmm_m_step(M_step)\n",
    "################ END OF LOCAL TEST CODE SECTION ######################͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "95a94c55",
   "metadata": {
    "id": "zQ1n7pSCHNcO",
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UnitTest passed successfully!\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "def loglikelihood(X, PI, MU, SIGMA, k):\n",
    "    \"\"\"Calculate a log likelihood of the \n",
    "    trained model based on the following\n",
    "    formula for posterior probability:\n",
    "    \n",
    "            log(Pr(X | mixing, mean, stdev)) = sum((i=1 to m), log(sum((j=1 to k),\n",
    "                                      mixing_j * N(x_i | mean_j,stdev_j))))\n",
    "\n",
    "    Make sure you are using natural log, instead of log base 2 or base 10.\n",
    "    \n",
    "    params:\n",
    "    X = numpy.ndarray[numpy.ndarray[float]] - m x n\n",
    "    MU = numpy.ndarray[numpy.ndarray[float]] - k x n\n",
    "    SIGMA = numpy.ndarray[numpy.ndarray[numpy.ndarray[float]]] - k x n x n\n",
    "    PI = numpy.ndarray[float] - k\n",
    "    k = int\n",
    "\n",
    "    returns:\n",
    "    log_likelihood = float\n",
    "    \"\"\"\n",
    "    # TODO: finish this function͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "    \n",
    "    answer = 0\n",
    "    for i in range(k):\n",
    "        answer += np.multiply((PI[i]),(prob(X,MU[i],SIGMA[i])))\n",
    "\n",
    "    return (np.sum(np.log(answer)))\n",
    "    \n",
    "########## DON'T WRITE ANY CODE OUTSIDE THE FUNCTION! ################͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "##### CODE BELOW IS USED FOR RUNNING LOCAL TEST DON'T MODIFY IT ######͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "tests.GMMTests().test_gmm_likelihood(loglikelihood)\n",
    "################ END OF LOCAL TEST CODE SECTION ######################͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "7a2e3849",
   "metadata": {
    "id": "qntf9HuFHNcV",
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "ename": "LinAlgError",
     "evalue": "0-dimensional array given. Array must be at least two-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/9z/1xzfb3xs7ngdny2d43cqsm6m0000gn/T/ipykernel_2224/2951808989.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;31m########## DON'T WRITE ANY CODE OUTSIDE THE FUNCTION! ################͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;31m##### CODE BELOW IS USED FOR RUNNING LOCAL TEST DON'T MODIFY IT ######͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m \u001b[0mtests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGMMTests\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_gmm_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloglikelihood\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;31m################ END OF LOCAL TEST CODE SECTION ######################͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/CSAI_1/assignment5_jco9/mixture_tests.py\u001b[0m in \u001b[0;36mtest_gmm_train\u001b[0;34m(self, train_model, likelihood)\u001b[0m\n\u001b[1;32m    452\u001b[0m         MU, SIGMA, PI, r = train_model(image_matrix, num_components,\n\u001b[1;32m    453\u001b[0m                                        \u001b[0mconvergence_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_convergence\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m                                        initial_values=(means, covariances, pis))\n\u001b[0m\u001b[1;32m    455\u001b[0m         \u001b[0mfinal_lkl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlikelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSIGMA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_components\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0mlikelihood_difference\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_lkl\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0minitial_lkl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/9z/1xzfb3xs7ngdny2d43cqsm6m0000gn/T/ipykernel_2224/2951808989.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(X, k, convergence_function, initial_values)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mnew_PI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mprev_likelihood\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloglikelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSIGMA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/9z/1xzfb3xs7ngdny2d43cqsm6m0000gn/T/ipykernel_2224/3732777404.py\u001b[0m in \u001b[0;36mloglikelihood\u001b[0;34m(X, PI, MU, SIGMA, k)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPI\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMU\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mSIGMA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/9z/1xzfb3xs7ngdny2d43cqsm6m0000gn/T/ipykernel_2224/1700796493.py\u001b[0m in \u001b[0;36mprob\u001b[0;34m(x, mu, sigma)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mco\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mco\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdivide\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0msub\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubtract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdet\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ai_env/lib/python3.7/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36mdet\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m   2110\u001b[0m     \"\"\"\n\u001b[1;32m   2111\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2112\u001b[0;31m     \u001b[0m_assert_stacked_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2113\u001b[0m     \u001b[0m_assert_stacked_square\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2114\u001b[0m     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_commonType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ai_env/lib/python3.7/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36m_assert_stacked_2d\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m             raise LinAlgError('%d-dimensional array given. Array must be '\n\u001b[0;32m--> 207\u001b[0;31m                     'at least two-dimensional' % a.ndim)\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_assert_stacked_square\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLinAlgError\u001b[0m: 0-dimensional array given. Array must be at least two-dimensional"
     ]
    }
   ],
   "source": [
    "#export\n",
    "def train_model(X, k, convergence_function, initial_values = None):\n",
    "    \"\"\"\n",
    "    Train the mixture model using the \n",
    "    expectation-maximization algorithm. \n",
    "    E.g., iterate E and M steps from \n",
    "    above until convergence.\n",
    "    If the initial_values are None, initialize them.\n",
    "    Else it's a tuple of the format (MU, SIGMA, PI).\n",
    "    Convergence is reached when convergence_function\n",
    "    returns terminate as True,\n",
    "    see default convergence_function example \n",
    "    in `helper_functions.py`\n",
    "\n",
    "    params:\n",
    "    X = numpy.ndarray[numpy.ndarray[float]] - m x n\n",
    "    k = int\n",
    "    convergence_function = func\n",
    "    initial_values = None or (MU, SIGMA, PI)\n",
    "\n",
    "    returns:\n",
    "    (new_MU, new_SIGMA, new_PI, responsibility)\n",
    "    new_MU = numpy.ndarray[numpy.ndarray[float]] - k x n\n",
    "    new_SIGMA = numpy.ndarray[numpy.ndarray[numpy.ndarray[float]]] - k x n x n\n",
    "    new_PI = numpy.ndarray[float] - k\n",
    "    responsibility = numpy.ndarray[numpy.ndarray[float]] - k x m\n",
    "    \"\"\"\n",
    "    # TODO: finish this function͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "    \n",
    "    if initial_values is None:\n",
    "        initial_values = initialize_parameters(X,k)\n",
    "    \n",
    "    MU,SIGMA,PI = initial_values\n",
    "    \n",
    "    new_MU = np.zeros((k,np.shape(X)[1]))\n",
    "    new_SIGMA = np.zeros((k,np.shape(X)[1],np.shape(X)[1]))\n",
    "    new_PI = np.zeros((k))\n",
    "    \n",
    "    prev_likelihood = loglikelihood(X, MU, SIGMA, PI, k)\n",
    "    r = E_step(X,MU,SIGMA,PI,k)\n",
    "    new_MU, new_SIGMA, new_PI = M_step(X, r, k)\n",
    "    MU, SIGMA, PI = new_MU, new_SIGMA, new_PI\n",
    "    curr = loglikelihood(X, MU, SIGMA, PI, k)\n",
    "    \n",
    "    \n",
    "    while (convergence_function(prev_likelihood, curr, 0) != True):\n",
    "        prev = curr\n",
    "        r = E_step(X,MU,SIGMA,PI,k)\n",
    "        new_MU, new_SIGMA, new_PI = M_step(X, r, k)\n",
    "        MU, SIGMA, PI = new_MU, new_SIGMA, new_PI\n",
    "        curr = loglikelihood(X, MU, SIGMA, PI, k)\n",
    "    \n",
    "    return (new_MU, new_SIGMA, new_PI, r)\n",
    "    \n",
    "\n",
    "########## DON'T WRITE ANY CODE OUTSIDE THE FUNCTION! ################͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "##### CODE BELOW IS USED FOR RUNNING LOCAL TEST DON'T MODIFY IT ######͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "tests.GMMTests().test_gmm_train(train_model, loglikelihood)\n",
    "################ END OF LOCAL TEST CODE SECTION ######################͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "e13d8c44",
   "metadata": {
    "id": "KnEL9hjXHNcX",
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UnitTest passed successfully!\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "def cluster(r):\n",
    "    \"\"\"\n",
    "    Based on a given responsibilities matrix\n",
    "    return an array of cluster indices.\n",
    "    Assign each datapoint to a cluster based,\n",
    "    on component with a max-likelihood \n",
    "    (maximum responsibility value).\n",
    "    \n",
    "    params:\n",
    "    r = numpy.ndarray[numpy.ndarray[float]] - k x m - responsibility matrix\n",
    "    \n",
    "    return:\n",
    "    clusters = numpy.ndarray[int] - m x 1 \n",
    "    \"\"\"\n",
    "    # TODO: finish this͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "    return np.argmax(r,axis=0)\n",
    "\n",
    "\n",
    "########## DON'T WRITE ANY CODE OUTSIDE THE FUNCTION! ################͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "##### CODE BELOW IS USED FOR RUNNING LOCAL TEST DON'T MODIFY IT ######͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "tests.GMMTests().test_gmm_cluster(cluster)\n",
    "################ END OF LOCAL TEST CODE SECTION ######################͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98408049",
   "metadata": {
    "id": "paVJfoIoHNca",
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def segment(X, MU, k, r):\n",
    "    \"\"\"\n",
    "    Segment the X matrix into k components. \n",
    "    Returns a matrix where each data point is \n",
    "    replaced with its max-likelihood component mean.\n",
    "    E.g., return the original matrix where each pixel's\n",
    "    intensity replaced with its max-likelihood \n",
    "    component mean. (the shape is still mxn, not \n",
    "    original image size)\n",
    "\n",
    "    params:\n",
    "    X = numpy.ndarray[numpy.ndarray[float]] - m x n\n",
    "    MU = numpy.ndarray[numpy.ndarray[float]] - k x n\n",
    "    k = int\n",
    "    r = numpy.ndarray[numpy.ndarray[float]] - k x m - responsibility matrix\n",
    "\n",
    "    returns:\n",
    "    new_X = numpy.ndarray[numpy.ndarray[float]] - m x n\n",
    "    \"\"\"\n",
    "    # TODO: finish this function͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "    \n",
    "    new_X \n",
    "\n",
    "########## DON'T WRITE ANY CODE OUTSIDE THE FUNCTION! ################͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "##### CODE BELOW IS USED FOR RUNNING LOCAL TEST DON'T MODIFY IT ######͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "tests.GMMTests().test_gmm_segment(train_model, segment)\n",
    "################ END OF LOCAL TEST CODE SECTION ######################͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba345fa8",
   "metadata": {
    "id": "X3FehT_rHNcd",
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def best_segment(X,k,iters):\n",
    "    \"\"\"Determine the best segmentation\n",
    "    of the image by repeatedly\n",
    "    training the model and\n",
    "    calculating its likelihood.\n",
    "    Return the segment with the\n",
    "    highest likelihood.\n",
    "\n",
    "    params:\n",
    "    X = numpy.ndarray[numpy.ndarray[float]] - m x n\n",
    "    k = int\n",
    "    iters = int\n",
    "\n",
    "    returns:\n",
    "    (likelihood, segment)\n",
    "    likelihood = float\n",
    "    segment = numpy.ndarray[numpy.ndarray[float]]\n",
    "    \"\"\"\n",
    "    # TODO: finish this function͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "    raise NotImplementedError()\n",
    "\n",
    "########## DON'T WRITE ANY CODE OUTSIDE THE FUNCTION! ################͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "##### CODE BELOW IS USED FOR RUNNING LOCAL TEST DON'T MODIFY IT ######͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "tests.GMMTests().test_gmm_best_segment(best_segment)\n",
    "################ END OF LOCAL TEST CODE SECTION ######################͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd84796",
   "metadata": {
    "id": "4ZZIUtr1HNcf"
   },
   "source": [
    "#### GMM - Visualizing the results\n",
    "\n",
    "Now that you are done with the EM implementation lets try to visualize what's happening if you repeat these steps multiple times.\n",
    "\n",
    "**You don't need to be implementing anything in the next 2 cells, but you are highly encouraged to play with parameters and datasets, to get a visual sense of what is happening at every step.**\n",
    "\n",
    "\n",
    "Feel free to explore and improve the function below, it will be used for visualizing GMM progress\n",
    "but it's not required and WON'T effect your grade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7b0cc0",
   "metadata": {
    "id": "h27gArYPHNcf"
   },
   "outputs": [],
   "source": [
    "def GMM_2D_dataset(dataset_index, K):\n",
    "    # Load the dataset from data folder͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "    X = np.loadtxt(\"data/%d_dataset_X.csv\" % dataset_index, delimiter=\",\")\n",
    "    print(\"There are %d datapoints in the current dataset, each of a size %d\" % X.shape)\n",
    "    print(\"\"\"\\nNote that that the Gaussian Ellipses and Normal Curves may not share the\n",
    "same color as the points they represent (within the same chart).\n",
    "In fact, the Gaussian Ellipses and Normal Curves represent the clusters\n",
    "in the top left chart (and thus share colors with those points).\"\"\")\n",
    "    # Load the labels͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "    # Clustering is unsupervised method, where no labels are provided͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "    # However, since we generated the data outselves we know the labels,͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "    # and load them for illustration purposes.͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "    y = np.int16(np.loadtxt(\"data/%d_dataset_y.csv\" % dataset_index, delimiter=\",\"))\n",
    "    # Feel free to edit the termination condition for the EM algorithm͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "    # Currently is just runs for n_iterations, before terminating͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "    \n",
    "    MU, SIGMA, PI = initialize_parameters(X, K)\n",
    "    \n",
    "    clusters_history = []\n",
    "    statistics_history = []\n",
    "    for _ in range(200):\n",
    "        r = E_step(X,MU,SIGMA,PI,K)\n",
    "        new_MU, new_SIGMA, new_PI = M_step(X, r, K)\n",
    "        PI, MU, SIGMA = new_PI, new_MU, new_SIGMA\n",
    "        clusters = cluster(r)\n",
    "        clusters_history.append(clusters)\n",
    "        statistics_history.append((PI, MU, SIGMA))\n",
    "\n",
    "    return X, y, clusters_history, statistics_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2e55cc",
   "metadata": {
    "id": "eCt92ePHHNch",
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# TRY DIFFERENT PARAMETERS͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "dataset_index = 3 # for different dataset change it to number from [0,5]\n",
    "K = 3 # Number of clusters - play with this number\n",
    "\n",
    "X, y, clusters_history, statistics_history = GMM_2D_dataset(dataset_index, K)\n",
    "\n",
    "def setup_subplot(plt, i, title, plot_number):\n",
    "    ax = plt.subplot(2, 2, plot_number)\n",
    "    ax.set_title(title)\n",
    "    ax.patch.set_facecolor('gray')\n",
    "    ax.patch.set_alpha(0.1)\n",
    "    return ax\n",
    "\n",
    "def plot_gaussian_ellipse(k, mean, covar, ax2, colors):\n",
    "    v,w = np.linalg.eig(covar)\n",
    "        \n",
    "    angle = np.arctan(w[1,0] / w[0,0])\n",
    "    angle = 180 * angle / np.pi\n",
    "    \n",
    "    color = colors[k % len(colors)]\n",
    "    for i in range(3,8):\n",
    "        plot_v = i * np.sqrt(v)\n",
    "        ellipse = pat.Ellipse(mean, plot_v[0], plot_v[1], angle, fill = True, alpha = 0.10, lw = 1.0, ls = 'dashdot', ec = 'black', fc = color, zorder = 0)\n",
    "        ax2.add_artist(ellipse)\n",
    "\n",
    "def plot_gaussian(X, mean, var, X_min, X_max, ax):\n",
    "    samples = np.linspace(X_min, X_max, 100)\n",
    "    ax.plot(samples, norm.pdf(samples, mean, var))\n",
    "    \n",
    "\n",
    "# This is an interactive cell to see the progress of training your GMM algorithm.͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "# Feel free to improve the visualization code and share it with your classmates on Piazza.͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "def get_cluster(i):\n",
    "    clusters = clusters_history[i] # Get the clusters from K-means' i-th iteration\n",
    "    cluster_means = statistics_history[i][1]\n",
    "    cluster_covar = statistics_history[i][2]\n",
    "    \n",
    "    plt.figure(None, figsize=(15,12)) # Set the plot size\n",
    "    plt.suptitle('Drag the slider to see the algorithm training progress')\n",
    "    \n",
    "    ax1 = setup_subplot(plt, i, 'GMM clusters - step %d' % i, 1)\n",
    "    ax2 = setup_subplot(plt, i, 'Ground truth clusters', 2)\n",
    "    ax3 = setup_subplot(plt, i, 'GMM Gausians X1 - step %d' % i, 3)\n",
    "    ax4 = setup_subplot(plt, i, 'GMM Gausians X2 - step %d' % i, 4)\n",
    "    \n",
    "    colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "    for k in range(K):\n",
    "        ax1.plot(X[clusters==k, 0], X[clusters==k, 1], '.')\n",
    "        \n",
    "        mean = cluster_means[k]\n",
    "        covar = cluster_covar[k]\n",
    "        \n",
    "        plot_gaussian_ellipse(k, mean, covar, ax2, colors)\n",
    "        plot_gaussian(X[clusters==k, 0], mean[0], covar[0,0], np.min(X[:, 0]), np.max(X[:, 0]), ax3)\n",
    "        plot_gaussian(X[clusters==k, 1], mean[1], covar[1,1], np.min(X[:, 1]), np.max(X[:, 1]), ax4)\n",
    "    \n",
    "    ax3.set_prop_cycle(None)\n",
    "    ax4.set_prop_cycle(None)\n",
    "    # Just to get a flavour of how the data looks like͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "    for i in np.unique(y):\n",
    "        ax2.plot(X[y==i,0], X[y==i,1],'.', zorder=10)\n",
    "        ax3.plot(X[y==i,0], np.zeros(X[y==i,0].shape[0]), '.', zorder = 10)\n",
    "        ax4.plot(X[y==i,1], np.zeros(X[y==i,1].shape[0]), '.', zorder = 10)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "interactive(get_cluster, {'manual': True}, i=(0,len(clusters_history)-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a118228",
   "metadata": {
    "id": "_OG0eYKOHNcj"
   },
   "source": [
    "### Let's visualize the image compression results of GMM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f29410",
   "metadata": {
    "id": "MH8wSDcXHNcj"
   },
   "outputs": [],
   "source": [
    "image_file = 'images/Starry.png' # Image path\n",
    "original_image_matrix = image_to_matrix(image_file) # Save original image\n",
    "image_matrix = original_image_matrix.reshape(-1,3) # collapse the dimension\n",
    "K = 10 # K\n",
    "\n",
    "_, best_seg = best_segment(image_matrix, K, iters = 10)\n",
    "new_image = best_seg.reshape(*original_image_matrix.shape) # reshape collapsed matrix to original size\n",
    "# Show the image͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "plt.figure(None,figsize=(9,12))\n",
    "plt.imshow(new_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bfd072",
   "metadata": {
    "id": "crCeltr8HNcl"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af579001",
   "metadata": {
    "id": "WpokxcYDHNcs"
   },
   "source": [
    "## Part 4 (extra for cs3600): Bayesian Information Criterion (12 pts)\n",
    "\n",
    "In our previous solutions, our only criterion for choosing a model was whether it maximizes the posterior likelihood regardless of how many parameters this requires. As a result, the \"best\" model may simply be the model with the most parameters, which would be overfit to the training data.\n",
    "\n",
    "To avoid overfitting, we can use the [Bayesian information criterion](https://en.wikipedia.org/wiki/Bayesian_information_criterion) (a.k.a. BIC) which penalizes models based on the number of parameters they use. In the case of the Gaussian mixture model, this is equal to the number of components times the number of variables per component (mean, variance and mixing coefficient).\n",
    "\n",
    "hint: \n",
    "\n",
    "## Part 4a: Implement BIC\n",
    "\n",
    "#### 4 points\n",
    "\n",
    "Implement `bayes_info_criterion()` to calculate the BIC of a trained Gaussian Mixture Model (based on the given parameters).\n",
    "\n",
    "Note: In the formula of BIC,  `k`  is the number of parameters estimated by the model. This is different from 'k', the number of clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84afcaed",
   "metadata": {
    "id": "cWWWYvXcHNct",
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def bayes_info_criterion(X, PI, MU, SIGMA, k):\n",
    "    \"\"\"\n",
    "    See description above\n",
    "    params:\n",
    "    X = numpy.ndarray[numpy.ndarray[float]] - m x n\n",
    "     numpy.ndarray[numpy.ndarray[float]] - k x n\n",
    "    SIGMA = numpy.ndarray[numpy.ndarray[numpy.ndarray[float]]] - k x n x n\n",
    "    PI = numpy.ndarray[float] - k\n",
    "    k = int\n",
    "    \n",
    "    return:\n",
    "    bayes_info_criterion = int\n",
    "    \"\"\"\n",
    "    # TODO: finish this function͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "    raise NotImplementedError()\n",
    "\n",
    "########## DON'T WRITE ANY CODE OUTSIDE THE FUNCTION! ################͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "##### CODE BELOW IS USED FOR RUNNING LOCAL TEST DON'T MODIFY IT ######͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "tests.GMMTests().test_bayes_info(bayes_info_criterion)\n",
    "################ END OF LOCAL TEST CODE SECTION ######################͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc92988c",
   "metadata": {
    "id": "01U3ixAdHNcv"
   },
   "source": [
    "## Part 4b: Test BIC\n",
    "\n",
    "#### 8 points\n",
    "\n",
    "Now implement `BIC_likelihood_model_test()`, in which you will use the BIC and likelihood to determine the optimal number of components in the `image_matrix` parameter. Using `train_model()`, iterate over the list of provided means (`comp_means`) to train a model that minimizes its BIC and a model that maximizes its likelihood. \n",
    "\n",
    "Return:\n",
    "\n",
    "1) The number of components which result in the minimum BIC\n",
    "\n",
    "2) The number of components which result in the highest likelihood\n",
    "\n",
    "`comp_means` is a list, where each element is a k x n matrix of means (where k = # of clusters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52297311",
   "metadata": {
    "id": "ExKFgbSCHNcw",
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def BIC_likelihood_model_test(image_matrix, comp_means):\n",
    "    \"\"\"Returns the number of components\n",
    "    corresponding to the minimum BIC \n",
    "    and maximum likelihood with respect\n",
    "    to image_matrix and comp_means.\n",
    "    \n",
    "    params:\n",
    "    image_matrix = numpy.ndarray[numpy.ndarray[float]] - m x n\n",
    "    comp_means = list(numpy.ndarray[numpy.ndarray[float]]) - list(k x n) (means for each value of k)\n",
    "\n",
    "    returns:\n",
    "    (n_comp_min_bic, n_comp_max_likelihood)\n",
    "    n_comp_min_bic = int\n",
    "    n_comp_max_likelihood = int\n",
    "    \"\"\"\n",
    "    # TODO: finish this method͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c3fced",
   "metadata": {
    "id": "tLCUO6h-HNcy"
   },
   "source": [
    "## Part 5: Return your name\n",
    "\n",
    "#### 1 point\n",
    "\n",
    "A simple task to wind down the assignment. Return your name from the function aptly called `return_your_name()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2a285990",
   "metadata": {
    "id": "Sr_9uWzOHNcy",
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def return_your_name():\n",
    "    # return your name͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "    # TODO: finish this͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "    return \"Jadon Co\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483c9d2f",
   "metadata": {
    "id": "ywkOL8FiHNc5"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09cc1c2",
   "metadata": {
    "id": "JLHrqPFTHNc5"
   },
   "source": [
    "## Congrats, you are done with the part of the assignment which is graded\n",
    "### Please follow the instructions in the README to submit your code for grading."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660a5b78",
   "metadata": {
    "id": "j2aY5pZZHNc6"
   },
   "source": [
    "- - -\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b0d9fd",
   "metadata": {
    "id": "7yVfXIqIHNc6"
   },
   "source": [
    "Next is as promised segmentation of the Point Cloud data. \n",
    "\n",
    "If you run into issues with `open3d` library below, please refer to official Open3d documentation http://www.open3d.org/docs/getting_started.html for details about the installation and library itself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7148bbf8",
   "metadata": {
    "id": "U58QXlMxHNc7"
   },
   "source": [
    "RGBD (**RGB** + **D**epth) data is usually stored as two separated images, one contains RGB (color) information and second one contains only depth, thus is a grayscale image. Let's load a data sample visualize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5b0c08",
   "metadata": {
    "id": "g4egnutjHNc7"
   },
   "outputs": [],
   "source": [
    "import open3d as o3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25096387",
   "metadata": {
    "id": "GPzqXL03HNdG"
   },
   "outputs": [],
   "source": [
    "# Function below load the data͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "def load_rgbd_image(image_path, depth_path):\n",
    "    color_raw = o3d.io.read_image(image_path)\n",
    "    depth_raw = o3d.io.read_image(depth_path)\n",
    "    #  details about function http://www.open3d.org/docs/tutorial/Basic/rgbd_odometry.html͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "    # We are using a data sample from the SUN RGB-D (http://rgbd.cs.princeton.edu/) dataset͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "    return color_raw, depth_raw\n",
    "\n",
    "# We can plot these images separately using the function below͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "def plot_rgbd(color_image, depth_image):\n",
    "    plt.figure(None,(15,15))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.title('Color image')\n",
    "    plt.imshow(color_image)\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.title('SUN depth image')\n",
    "    plt.imshow(depth_image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ac499d",
   "metadata": {
    "id": "jNzqnMX7HNdI"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "from PIL import Image\n",
    "%matplotlib inline\n",
    "rgbd_dataset = glob.glob('rgbd/image/*.jpg') # TODO fix it\n",
    "image_number = 3 # [0,4] there are five different images in the folder\n",
    "\n",
    "image_file = rgbd_dataset[image_number]\n",
    "depth_file = image_file.replace('image','depth')[:-4] + '.png'\n",
    "assert os.path.isfile(image_file); \n",
    "assert os.path.isfile(depth_file);\n",
    "color_image, depth_image = load_rgbd_image(image_file, depth_file)\n",
    "plot_rgbd(color_image, depth_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ad1a69",
   "metadata": {
    "id": "9GPrqYCQHNdN"
   },
   "outputs": [],
   "source": [
    "# Next we can convert the depth image into a point cloud͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉 \n",
    "def show_point_cloud(color_raw, depth_raw):\n",
    "    rgbd_image = o3d.geometry.RGBDImage.create_from_sun_format(color_raw, depth_raw);\n",
    "    pcd = o3d.geometry.PointCloud.create_from_rgbd_image(rgbd_image, \n",
    "                 o3d.camera.PinholeCameraIntrinsic(o3d.camera.PinholeCameraIntrinsicParameters.PrimeSenseDefault))\n",
    "    # Flip it, otherwise the pointcloud will be upside down͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "    pcd.transform([[1, 0, 0, 0], [0, -1, 0, 0], [0, 0, -1, 0], [0, 0, 0, 1]])\n",
    "    o3d.visualization.draw_geometries([pcd])\n",
    "    return pcd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16e78d0",
   "metadata": {
    "id": "mn3oPBe8HNdS"
   },
   "outputs": [],
   "source": [
    "pcd = show_point_cloud(color_image, depth_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ee0c25",
   "metadata": {
    "id": "hkEWvOGKHNdW"
   },
   "outputs": [],
   "source": [
    "# Lets have a look at the structure of the point cloud data͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "pcd_points = np.asarray(pcd.points)\n",
    "print(\"Point cloud data - shape:\", pcd_points.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761b2138",
   "metadata": {
    "id": "BADBLF0VHNdX"
   },
   "source": [
    "Point cloud data is represented as an unsorted set of the size M x N., where M is the number of points and N is the x,y,z value for each point. If you are interested you can access the color data in `pcd.colors`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240931fa",
   "metadata": {
    "id": "8-PI0jUiHNdY"
   },
   "source": [
    "Let us try to perform a segmentation on the image we just loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a68664f",
   "metadata": {
    "id": "4CSsyGtEHNdY"
   },
   "outputs": [],
   "source": [
    "# Setting the number of clusters͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "K = 5\n",
    "# Note: it's just a simple train model run͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "# To improve it you can adapt the best_segment()͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉 \n",
    "# to generate the clusters with the best model͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "initial_params = initialize_parameters(pcd_points, K)\n",
    "MU, SIGMA, PI, r = train_model(pcd_points, K,\n",
    "                               convergence_function=default_convergence,\n",
    "                               initial_values=initial_params)\n",
    "clusters = cluster(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd656be6",
   "metadata": {
    "id": "PWROpiDyHNda"
   },
   "outputs": [],
   "source": [
    "# Generate a set of size K of distinct color to plot the clusters͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "# Adapted from https://stackoverflow.com/questions/876853/generating-color-ranges-in-python͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄄͏︂͏󠄉\n",
    "import colorsys\n",
    "HSV_tuples = [(x*1.0/K, 1.0, 1.0) for x in range(K)]\n",
    "color_maps = list(map(lambda x: colorsys.hsv_to_rgb(*x), HSV_tuples))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82ea345",
   "metadata": {
    "id": "FOBHN7n8HNdd"
   },
   "source": [
    "### Visualizing the segmented point cloud data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc53638",
   "metadata": {
    "id": "Q_El0ZyvHNdf"
   },
   "outputs": [],
   "source": [
    "or_pcd = o3d.geometry.PointCloud() # Create new point cloud handler\n",
    "or_pcd.points = o3d.utility.Vector3dVector(pcd_points) # set point cloud data\n",
    "colors = np.zeros_like(pcd_points) # initialize colors to 0\n",
    "for i, point in enumerate(np.unique(clusters)):\n",
    "    random_color = color_maps[i]\n",
    "    cluster_mask = (clusters == point) # get the mask of the cluster i\n",
    "    colors[cluster_mask,:] = random_color # set random color to all the point of this segment\n",
    "or_pcd.colors = o3d.utility.Vector3dVector(colors) # set color data\n",
    "o3d.visualization.draw_geometries([or_pcd]) # visualize point cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2572f61",
   "metadata": {
    "id": "EZXEC7QnHNdj"
   },
   "source": [
    "Some questions to think about:\n",
    "- Would adding a color help or harm the segmentation results?\n",
    "- How about the case: segment RGB data -> add depth -> convert to Point Cloud -> cluster? Would that help/harm?\n",
    "- Could you think of a way you could compress the point cloud data?\n",
    "\n",
    "Things to try:\n",
    "- Segmentation here is done in purely unsupervised manner, you could manually combine multiple gaussian\n",
    "- How about merging multiple scenes into a single one? You could crop one segment from one scene and place it inside another scene.\n",
    "- Try K-means on point cloud data and see what results does it produces\n",
    "- Can we omit the step of conversion to point cloud? And use depth only? Or depth with x,y coordinates?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
